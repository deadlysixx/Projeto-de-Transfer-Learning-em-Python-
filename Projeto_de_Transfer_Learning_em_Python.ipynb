O projeto consiste em aplicar o método de Transfer Learning em uma rede de Deep Learning na linguagem Python no ambiente COLAB.


# Importando os pacotes necessários

%matplotlib inline

import os
import random
import numpy as np
import keras
from tensorflow.keras.utils import to_categorical

import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Activation
from keras.layers import Conv2D, MaxPooling2D
from keras.models import Model

from six.moves import urllib
import gzip

from shutil import copyfile

# import the needed packages
# import matplotlib.pyplot as plt
import matplotlib.image as img
from tensorflow import keras
     
Carregando os dados

# Baixando o conjunto de dados de cães e gatos

!echo "Downloading catsanddogs for image notebooks"
!curl -L -o kagglecatsanddogs_5340.zip --progress-bar https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip #download

# As instruções para preparar o conjunto de dados são para Linux ou macOS

!unzip kagglecatsanddogs_5340.zip
!rm kagglecatsanddogs_5340.zip
!ls
     
A saída de streaming foi truncada nas últimas 5000 linhas.
Exploração e limpeza dos dados

# exibindo a quantidade de imagem 

print(len(os.listdir('/content/PetImages/Cat')))
print(len(os.listdir('/content/PetImages/Dog')))

     
12501
12501

# Crinando diretórios para separar as imagens em Treino e Teste

try:
    os.mkdir('cats-v-dogs')
    os.mkdir('cats-v-dogs/training')
    os.mkdir('cats-v-dogs/testing')
    os.mkdir('cats-v-dogs/training/cats')
    os.mkdir('cats-v-dogs/training/dogs')
    os.mkdir('cats-v-dogs/testing/cats')
    os.mkdir('cats-v-dogs/testing/dogs')
except OSError:
    pass
     

#  Função para separar o conjunto de dados em treino e teste
#  E limpando as imagens com comprimento zero

def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):
    files = []
    for filename in os.listdir(SOURCE):
        file = SOURCE + filename
        if os.path.getsize(file) > 0:
            files.append(filename)
        else:
            print(filename + " is zero length, so ignoring.")

    training_length = int(len(files) * SPLIT_SIZE)
    testing_length = int(len(files) - training_length)
    shuffled_set = random.sample(files, len(files))
    training_set = shuffled_set[0:training_length]
    testing_set = shuffled_set[-testing_length:]

    for filename in training_set:
        this_file = SOURCE + filename
        destination = TRAINING + filename
        copyfile(this_file, destination)

    for filename in testing_set:
        this_file = SOURCE + filename
        destination = TESTING + filename
        copyfile(this_file, destination)


CAT_SOURCE_DIR = "PetImages/Cat/"
TRAINING_CATS_DIR = "cats-v-dogs/training/cats/"
TESTING_CATS_DIR = "cats-v-dogs/testing/cats/"
DOG_SOURCE_DIR = "PetImages/Dog/"
TRAINING_DOGS_DIR = "cats-v-dogs/training/dogs/"
TESTING_DOGS_DIR = "cats-v-dogs/testing/dogs/"

split_size = .9
split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)
split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)
     
666.jpg is zero length, so ignoring.
11702.jpg is zero length, so ignoring.

# exibindo a quantidade de imagem por diretórios


print(len(os.listdir('cats-v-dogs/training/cats/')))
print(len(os.listdir('cats-v-dogs/training/dogs/')))
print(len(os.listdir('cats-v-dogs/testing/cats/')))
print(len(os.listdir('cats-v-dogs/testing/dogs/')))
     
11250
11250
1250
1250

# define e move para o diretório do dataset
datasetdir = '/content/PetImages'
os.chdir(datasetdir)


# atalho para a classe ImageDataGenerator
ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator
     
Transformando e exibindo os dados

plt.subplot(1,2,1)
plt.imshow(img.imread('Cat/665.jpg'))
plt.subplot(1,2,2)
plt.imshow(img.imread('Dog/11703.jpg'))
     
<matplotlib.image.AxesImage at 0x7f55efe6afd0>


images = []
for i in range(10):
  im = img.imread('Cat/660.jpg'.format(i))
  images.append(im)
  print('image shape', im.shape, 'maximum color level', im.max())
     
image shape (346, 259, 4) maximum color level 255
image shape (346, 259, 4) maximum color level 255
image shape (346, 259, 4) maximum color level 255
image shape (346, 259, 4) maximum color level 255
image shape (346, 259, 4) maximum color level 255
image shape (346, 259, 4) maximum color level 255
image shape (346, 259, 4) maximum color level 255
image shape (346, 259, 4) maximum color level 255
image shape (346, 259, 4) maximum color level 255
image shape (346, 259, 4) maximum color level 255

# função auxiliar para carregar a imagem e devolvê-la e inserir o vetor
def get_image(path):
    img = image.load_img(path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    return img, x
     
Agora precisamos transformar nossas imagens, em arquivos de disco, em lotes de matrizes de dados na memória que possam ser alimentadas na rede durante o treinamento.

O ImageDataGenerator pode ser facilmente usado para essa finalidade. Vamos importar esta classe e criar uma instância do gerador:


gen = ImageDataGenerator()

     
Agora, usaremos o método flow_from_directory gen do objeto para iniciar a geração de lotes.

Este método retornará um iterador que retornará um lote toda vez que for iterado. Para ver como os dados estão organizados, podemos simplesmente criar esse iterador e obter um primeiro lote para examiná-lo:


iterator = gen.flow_from_directory(
    os.getcwd(), 
    target_size=(256,256), 
    classes=('Dog','Cat')
)

# Encontrado 25000 imagens pertencentes a 2 classes.
     
Found 25000 images belonging to 2 classes.

# podemos adivinhar que o iterador tem uma próxima função,
# porque todos os iteradores python têm um.
 
batch = iterator.next()
len(batch)
     
2

# Vereficando os tipos lote dos dois elementos

print(type(batch[0]))
print(type(batch[1]))
     
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>

# Imprimindo a forma e o tipo das duas matrizes numpy.

print(batch[0].shape)
print(batch[0].dtype)
print(batch[0].max())
print(batch[1].shape)
print(batch[1].dtype)
     
(32, 256, 256, 3)
float32
255.0
(32, 2)
float32
Obviamente, o primeiro elemento é um array de 32 imagens com 256x256 pixels e 3 canais de cores, codificados como floats no intervalo de 0 a 255. Portanto, o ImageDataGenerator forçou a imagem para 256x256 pixels conforme solicitado, mas não normalizou a cor níveis entre 0 e 1. Teremos que fazer isso mais tarde.

O segundo elemento contém os 32 rótulos correspondentes.

Antes de dar uma olhada detalhada nos rótulos, podemos plotar a primeira imagem:


# precisamos converter o array de imagens para inteiros
# antes de plotar como imshow ou pega arrays de inteiros,
# ou arrays de floats normalizados para 1.

plt.imshow(batch[0][0].astype(int))
     
<matplotlib.image.AxesImage at 0x7f55ecec5490>


batch[1][0]
     
array([1., 0.], dtype=float32)
Para validar os rótulos do conjunto de dados, queremos verificar se, para alguns lotes, os rótulos estão definidos corretamente. Portanto, precisamos de uma função que possa plotar um número bastante grande de imagens e rotulá-las. Aqui está:


def plot_images(batch):
    imgs = batch[0]
    labels = batch[1]
    ncols, nrows = 4,8
    fig = plt.figure( figsize=(ncols*3, nrows*3), dpi=90)
    for i, (img,label) in enumerate(zip(imgs,labels)):
      plt.subplot(nrows, ncols, i+1)
      plt.imshow(img.astype(int))
      assert(label[0]+label[1]==1.)
      categ = 'Dog' if label[0]>0.5 else 'Cat'
      plt.title( '{} {}'.format(str(label), categ))
      plt.axis('off')
     

plot_images(iterator.next())

     

Treinando o conjuto de dados

# Dividindo as amostras de treinamento e validação com ImageDataGenerator

imgdatagen = ImageDataGenerator(
    rescale = 1/255., 
    validation_split = 0.2,
)
     



batch_size = 8
height, width = (256,256)

TRAINING_DIR = "/content/cats-v-dogs/training/"
train_dataset = imgdatagen.flow_from_directory(
    TRAINING_DIR,
    target_size = (height, width), 
    classes = ('dogs','cats'),
    batch_size = batch_size,
    subset = 'training'
)

VALIDATION_DIR = "/content/cats-v-dogs/testing/"
val_dataset = imgdatagen.flow_from_directory(
    VALIDATION_DIR,
    target_size = (height, width), 
    classes = ('dogs','cats'),
    batch_size = batch_size,
    subset = 'validation'
)
     
Found 18000 images belonging to 2 classes.
Found 500 images belonging to 2 classes.

# rede neural convolucional simples
# As redes neurais convolucionais profundas são a escolha certa quando se trata de classificar imagens

model = keras.models.Sequential()

initializers = {
    
}
model.add( 
    keras.layers.Conv2D(
        24, 5, input_shape=(256,256,3), 
        activation='relu', 
    )
)
model.add( keras.layers.MaxPooling2D(2) )
model.add( 
    keras.layers.Conv2D(
        48, 5, activation='relu', 
    )
)
model.add( keras.layers.MaxPooling2D(2) )
model.add( 
    keras.layers.Conv2D(
        96, 5, activation='relu', 
    )
)
model.add( keras.layers.Flatten() )
model.add( keras.layers.Dropout(0.9) )

model.add( keras.layers.Dense(
    2, activation='softmax',
    )
)

model.summary()
     
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 252, 252, 24)      1824      
                                                                 
 max_pooling2d (MaxPooling2D  (None, 126, 126, 24)     0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 122, 122, 48)      28848     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 61, 61, 48)       0         
 2D)                                                             
                                                                 
 conv2d_2 (Conv2D)           (None, 57, 57, 96)        115296    
                                                                 
 flatten (Flatten)           (None, 311904)            0         
                                                                 
 dropout (Dropout)           (None, 311904)            0         
                                                                 
 dense (Dense)               (None, 2)                 623810    
                                                                 
=================================================================
Total params: 769,778
Trainable params: 769,778
Non-trainable params: 0
_________________________________________________________________

model.compile(loss='binary_crossentropy',
              optimizer=keras.optimizers.Adamax(learning_rate=0.001),
              metrics=['acc'])
     

history = model.fit(
    train_dataset, 
    validation_data = val_dataset,
    workers=10,
    epochs=10,
)
     
Epoch 1/10
   7/2250 [..............................] - ETA: 1:41 - loss: 0.2016 - acc: 0.9107
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
  warnings.warn(str(msg))
2250/2250 [==============================] - 78s 35ms/step - loss: 0.2661 - acc: 0.8918 - val_loss: 0.3430 - val_acc: 0.8600
Epoch 2/10
2250/2250 [==============================] - 77s 34ms/step - loss: 0.2467 - acc: 0.8989 - val_loss: 0.3076 - val_acc: 0.8680
Epoch 3/10
2250/2250 [==============================] - 76s 34ms/step - loss: 0.2335 - acc: 0.9071 - val_loss: 0.3136 - val_acc: 0.8700
Epoch 4/10
2250/2250 [==============================] - 77s 34ms/step - loss: 0.2242 - acc: 0.9084 - val_loss: 0.3464 - val_acc: 0.8520
Epoch 5/10
2250/2250 [==============================] - 77s 34ms/step - loss: 0.2131 - acc: 0.9144 - val_loss: 0.3303 - val_acc: 0.8660
Epoch 6/10
2250/2250 [==============================] - 77s 34ms/step - loss: 0.2082 - acc: 0.9168 - val_loss: 0.3209 - val_acc: 0.8700
Epoch 7/10
2250/2250 [==============================] - 76s 34ms/step - loss: 0.1922 - acc: 0.9241 - val_loss: 0.3241 - val_acc: 0.8680
Epoch 8/10
2250/2250 [==============================] - 77s 34ms/step - loss: 0.1874 - acc: 0.9238 - val_loss: 0.3234 - val_acc: 0.8580
Epoch 9/10
2250/2250 [==============================] - 77s 34ms/step - loss: 0.1755 - acc: 0.9321 - val_loss: 0.3428 - val_acc: 0.8680
Epoch 10/10
2250/2250 [==============================] - 77s 34ms/step - loss: 0.1614 - acc: 0.9357 - val_loss: 0.3158 - val_acc: 0.8800
Exibindo o resultados do treinento
Agora que o treinamento está feito, precisamos de uma maneira de ver como o treinamento funcionou. Para isso, essa pequena função para plotar a perda e a precisão dos conjuntos de dados de treinamento e validação, em função da época


def plot_history(history, yrange):
    '''Plot loss and accuracy as a function of the epoch,
    for the training and validation datasets.
    '''
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    # Get number of epochs
    epochs = range(len(acc))

    # Plot training and validation accuracy per epoch
    plt.plot(epochs, acc)
    plt.plot(epochs, val_acc)
    plt.title('Training and validation accuracy')
    plt.ylim(yrange)
    
    # Plot training and validation loss per epoch
    plt.figure()

    plt.plot(epochs, loss)
    plt.plot(epochs, val_loss)
    plt.title('Training and validation loss')
    
    plt.show()
     

plot_history(history, (0.65, 1.))

     


Aumento de dados
O aumento de dados consiste em gerar novos exemplos de treinamento a partir dos já existentes, de forma a aumentar artificialmente o tamanho da amostra de treinamento. Isso é muito fácil de fazer com o ImageDataGenerator. Por exemplo, podemos começar virando aleatoriamente para a esquerda e para a direita em nossas imagens


imgdatagen = ImageDataGenerator(
    rescale = 1/255., 
    horizontal_flip = True, 
    validation_split = 0.2,
)
     
Resultado da transformação em uma determinada imagem


image = img.imread('Cat/12.jpg')

def plot_transform():
    '''apply the transformation 8 times randomly'''
    nrows, ncols = 2,4
    fig = plt.figure(figsize=(ncols*3, nrows*3), dpi=90)
    for i in range(nrows*ncols): 
        timage = imgdatagen.random_transform(image)
        plt.subplot(nrows, ncols, i+1)
        plt.imshow(timage)
        plt.axis('off')
        
plot_transform()
     

Transformação um pouco mais complexa. o ImageDataGenerator irá inverter, ampliar e girar as imagens de forma aleatória


imgdatagen = ImageDataGenerator(
    rescale = 1/255., 
    horizontal_flip = True, 
    zoom_range = 0.3, 
    rotation_range = 15.,
    validation_split = 0.1,
)

plot_transform()

     

Vimos que essas transformações produzem novas imagens perfeitamente aceitáveis. Então, vamos treinar novamente a rede com aumento de dados. É importante notar que, devido à natureza aleatória das transformações, a rede verá cada imagem apenas uma vez. Podemos, portanto, esperar que será difícil para a rede overfitting.


batch_size = 8
height, width = (256,256)

TRAINING_DIR = "/content/cats-v-dogs/training/"
train_dataset = imgdatagen.flow_from_directory(
    TRAINING_DIR,
    target_size = (height, width), 
    classes = ('dogs','cats'),
    batch_size = batch_size,
    subset = 'training'
)

VALIDATION_DIR = "/content/cats-v-dogs/testing/"
val_dataset = imgdatagen.flow_from_directory(
    VALIDATION_DIR,
    target_size = (height, width), 
    classes = ('dogs','cats'),
    batch_size = batch_size,
    subset = 'validation'
)
     
Found 20250 images belonging to 2 classes.
Found 250 images belonging to 2 classes.

model = keras.models.Sequential()

initializers = {
    
}
model.add( 
    keras.layers.Conv2D(
        24, 5, input_shape=(256,256,3), 
        activation='relu', 
    )
)
model.add( keras.layers.MaxPooling2D(2) )
model.add( 
    keras.layers.Conv2D(
        48, 5, activation='relu', 
    )
)
model.add( keras.layers.MaxPooling2D(2) )
model.add( 
    keras.layers.Conv2D(
        96, 5, activation='relu', 
    )
)
model.add( keras.layers.Flatten() )
model.add( keras.layers.Dropout(0.2) )

model.add( keras.layers.Dense(
    2, activation='softmax',
    )
)

model.summary()
     
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_6 (Conv2D)           (None, 252, 252, 24)      1824      
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 126, 126, 24)     0         
 2D)                                                             
                                                                 
 conv2d_7 (Conv2D)           (None, 122, 122, 48)      28848     
                                                                 
 max_pooling2d_5 (MaxPooling  (None, 61, 61, 48)       0         
 2D)                                                             
                                                                 
 conv2d_8 (Conv2D)           (None, 57, 57, 96)        115296    
                                                                 
 flatten_2 (Flatten)         (None, 311904)            0         
                                                                 
 dropout_2 (Dropout)         (None, 311904)            0         
                                                                 
 dense_2 (Dense)             (None, 2)                 623810    
                                                                 
=================================================================
Total params: 769,778
Trainable params: 769,778
Non-trainable params: 0
_________________________________________________________________

model.compile(loss='binary_crossentropy',
              optimizer=keras.optimizers.Adamax(learning_rate=0.001),
              metrics=['acc'])
     

history_augm = model.fit(
    train_dataset, 
    validation_data = val_dataset,
    workers=10,
    epochs=40,
)
     
Epoch 1/40
 410/2532 [===>..........................] - ETA: 4:16 - loss: 0.6992 - acc: 0.5312
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532
  " Skipping tag %s" % (size, len(data), tag)
/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
  warnings.warn(str(msg))
2532/2532 [==============================] - 307s 121ms/step - loss: 0.6159 - acc: 0.6529 - val_loss: 0.5501 - val_acc: 0.7320
Epoch 2/40
2532/2532 [==============================] - 305s 120ms/step - loss: 0.5130 - acc: 0.7497 - val_loss: 0.4491 - val_acc: 0.7720
Epoch 3/40
2532/2532 [==============================] - 299s 118ms/step - loss: 0.4544 - acc: 0.7880 - val_loss: 0.4494 - val_acc: 0.7880
Epoch 4/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.4149 - acc: 0.8138 - val_loss: 0.4047 - val_acc: 0.8000
Epoch 5/40
2532/2532 [==============================] - 294s 116ms/step - loss: 0.3899 - acc: 0.8272 - val_loss: 0.4131 - val_acc: 0.8120
Epoch 6/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.3614 - acc: 0.8402 - val_loss: 0.4038 - val_acc: 0.8160
Epoch 7/40
2532/2532 [==============================] - 294s 116ms/step - loss: 0.3383 - acc: 0.8531 - val_loss: 0.3315 - val_acc: 0.8600
Epoch 8/40
2532/2532 [==============================] - 294s 116ms/step - loss: 0.3137 - acc: 0.8647 - val_loss: 0.3808 - val_acc: 0.8320
Epoch 9/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.3020 - acc: 0.8726 - val_loss: 0.3722 - val_acc: 0.8560
Epoch 10/40
2532/2532 [==============================] - 294s 116ms/step - loss: 0.2781 - acc: 0.8843 - val_loss: 0.3952 - val_acc: 0.8320
Epoch 11/40
2532/2532 [==============================] - 294s 116ms/step - loss: 0.2702 - acc: 0.8862 - val_loss: 0.2901 - val_acc: 0.8760
Epoch 12/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.2563 - acc: 0.8927 - val_loss: 0.3270 - val_acc: 0.8640
Epoch 13/40
2532/2532 [==============================] - 293s 115ms/step - loss: 0.2479 - acc: 0.8948 - val_loss: 0.2705 - val_acc: 0.8760
Epoch 14/40
2532/2532 [==============================] - 296s 117ms/step - loss: 0.2357 - acc: 0.9023 - val_loss: 0.3154 - val_acc: 0.8560
Epoch 15/40
2532/2532 [==============================] - 301s 118ms/step - loss: 0.2227 - acc: 0.9058 - val_loss: 0.2722 - val_acc: 0.8800
Epoch 16/40
2532/2532 [==============================] - 303s 119ms/step - loss: 0.2193 - acc: 0.9105 - val_loss: 0.2472 - val_acc: 0.8840
Epoch 17/40
2532/2532 [==============================] - 302s 119ms/step - loss: 0.2150 - acc: 0.9130 - val_loss: 0.3159 - val_acc: 0.8760
Epoch 18/40
2532/2532 [==============================] - 301s 119ms/step - loss: 0.2071 - acc: 0.9166 - val_loss: 0.2273 - val_acc: 0.8960
Epoch 19/40
2532/2532 [==============================] - 298s 117ms/step - loss: 0.1984 - acc: 0.9184 - val_loss: 0.2064 - val_acc: 0.9080
Epoch 20/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.1960 - acc: 0.9207 - val_loss: 0.2254 - val_acc: 0.9080
Epoch 21/40
2532/2532 [==============================] - 294s 116ms/step - loss: 0.1870 - acc: 0.9253 - val_loss: 0.2593 - val_acc: 0.8960
Epoch 22/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.1821 - acc: 0.9248 - val_loss: 0.2554 - val_acc: 0.8880
Epoch 23/40
2532/2532 [==============================] - 296s 117ms/step - loss: 0.1842 - acc: 0.9257 - val_loss: 0.2183 - val_acc: 0.9080
Epoch 24/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.1735 - acc: 0.9305 - val_loss: 0.2581 - val_acc: 0.8960
Epoch 25/40
2532/2532 [==============================] - 302s 119ms/step - loss: 0.1728 - acc: 0.9304 - val_loss: 0.2465 - val_acc: 0.8920
Epoch 26/40
2532/2532 [==============================] - 299s 118ms/step - loss: 0.1697 - acc: 0.9339 - val_loss: 0.3638 - val_acc: 0.8760
Epoch 27/40
2532/2532 [==============================] - 296s 116ms/step - loss: 0.1670 - acc: 0.9335 - val_loss: 0.2400 - val_acc: 0.8800
Epoch 28/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.1602 - acc: 0.9333 - val_loss: 0.2081 - val_acc: 0.9040
Epoch 29/40
2532/2532 [==============================] - 298s 117ms/step - loss: 0.1586 - acc: 0.9375 - val_loss: 0.2104 - val_acc: 0.9200
Epoch 30/40
2532/2532 [==============================] - 296s 116ms/step - loss: 0.1577 - acc: 0.9382 - val_loss: 0.1909 - val_acc: 0.9320
Epoch 31/40
2532/2532 [==============================] - 298s 117ms/step - loss: 0.1554 - acc: 0.9376 - val_loss: 0.1787 - val_acc: 0.9320
Epoch 32/40
2532/2532 [==============================] - 296s 116ms/step - loss: 0.1499 - acc: 0.9402 - val_loss: 0.2487 - val_acc: 0.8960
Epoch 33/40
2532/2532 [==============================] - 297s 117ms/step - loss: 0.1485 - acc: 0.9401 - val_loss: 0.2007 - val_acc: 0.9200
Epoch 34/40
2532/2532 [==============================] - 297s 117ms/step - loss: 0.1419 - acc: 0.9427 - val_loss: 0.2156 - val_acc: 0.9160
Epoch 35/40
2532/2532 [==============================] - 297s 117ms/step - loss: 0.1405 - acc: 0.9455 - val_loss: 0.1908 - val_acc: 0.9120
Epoch 36/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.1434 - acc: 0.9415 - val_loss: 0.2200 - val_acc: 0.9200
Epoch 37/40
2532/2532 [==============================] - 296s 117ms/step - loss: 0.1405 - acc: 0.9437 - val_loss: 0.2017 - val_acc: 0.9160
Epoch 38/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.1348 - acc: 0.9478 - val_loss: 0.1350 - val_acc: 0.9480
Epoch 39/40
2532/2532 [==============================] - 297s 117ms/step - loss: 0.1363 - acc: 0.9473 - val_loss: 0.1851 - val_acc: 0.9320
Epoch 40/40
2532/2532 [==============================] - 295s 116ms/step - loss: 0.1341 - acc: 0.9472 - val_loss: 0.1952 - val_acc: 0.9240

plot_history(history_augm, (0.65, 1))

     


Usando um modelo pré-treinado: ResNet50

from tensorflow.keras.applications.resnet50 import ResNet50
from keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
import numpy as np

model = ResNet50(weights='imagenet')
     
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5
102973440/102967424 [==============================] - 4s 0us/step
102981632/102967424 [==============================] - 4s 0us/step
Em seguida, definimos uma pequena função de utilidade para avaliar o modelo em uma imagem de entrada e chamamos essa função em algumas imagens em nosso conjunto de dados


def evaluate(img_fname):
    img = image.load_img(img_fname, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    preds = model.predict(x)
    # print the probability and category name for the 5 categories 
    # with highest probability: 
    print('Predicted:', decode_predictions(preds, top=5)[0])
    plt.imshow(img)
     

evaluate('/content/PetImages/Dog/10007.jpg')

     
Predicted: [('n02102040', 'English_springer', 0.25571927), ('n02100236', 'German_short-haired_pointer', 0.16240002), ('n02093428', 'American_Staffordshire_terrier', 0.098809384), ('n02107574', 'Greater_Swiss_Mountain_dog', 0.08030297), ('n02099712', 'Labrador_retriever', 0.07754765)]


evaluate('/content/PetImages/Dog/10188.jpg')

     
Predicted: [('n02099712', 'Labrador_retriever', 0.28370374), ('n02109047', 'Great_Dane', 0.19969639), ('n02099267', 'flat-coated_retriever', 0.11479504), ('n02107142', 'Doberman', 0.05612186), ('n02089078', 'black-and-tan_coonhound', 0.043165218)]


evaluate('/content/PetImages/Dog/1014.jpg')

     
Predicted: [('n02096437', 'Dandie_Dinmont', 0.7582223), ('n02098413', 'Lhasa', 0.13737771), ('n02097474', 'Tibetan_terrier', 0.03101932), ('n02093754', 'Border_terrier', 0.018662168), ('n02113712', 'miniature_poodle', 0.015777905)]


evaluate('/content/PetImages/Cat/0.jpg')

     
Predicted: [('n02094258', 'Norwich_terrier', 0.34793243), ('n02085620', 'Chihuahua', 0.11957316), ('n02123045', 'tabby', 0.08625675), ('n02113186', 'Cardigan', 0.07970776), ('n02094114', 'Norfolk_terrier', 0.027367007)]


evaluate('/content/PetImages/Cat/1.jpg')

     
Predicted: [('n02123045', 'tabby', 0.7306045), ('n02123159', 'tiger_cat', 0.15751234), ('n02124075', 'Egyptian_cat', 0.07735979), ('n03958227', 'plastic_bag', 0.0035997469), ('n02127052', 'lynx', 0.0033316924)]


# download the image from my github repository
import urllib.request as req
url = 'https://raw.githubusercontent.com/cbernet/maldives/master/dogs_vs_cats/datafrog_chien_chat.png' 
req.urlretrieve(url, 'dog_cartoon.jpg')

evaluate('dog_cartoon.jpg')
     
Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json
40960/35363 [==================================] - 0s 0us/step
49152/35363 [=========================================] - 0s 0us/step
Predicted: [('n02106662', 'German_shepherd', 0.26686338), ('n03803284', 'muzzle', 0.26613066), ('n02113023', 'Pembroke', 0.13620536), ('n02109047', 'Great_Dane', 0.07119835), ('n02114712', 'red_wolf', 0.04037643)]
